2019-11-28 09:28:50 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:28:50 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:28:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:28:50 [scrapy.extensions.telnet] INFO: Telnet Password: 536d0f15cd5d4f02
2019-11-28 09:28:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:28:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:28:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:28:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:28:51 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:28:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:28:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:28:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:28:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:28:52 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:28:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894066,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.775486,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 28, 52, 856551),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 74854400,
 'memusage/startup': 74854400,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 28, 51, 81065)}
2019-11-28 09:28:52 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:30:20 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:30:20 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:30:20 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:30:20 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:30:21 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:30:21 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:30:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:30:21 [scrapy.extensions.telnet] INFO: Telnet Password: 1ece065fd33a8794
2019-11-28 09:30:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:30:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:30:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:30:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:30:22 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:30:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:30:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:30:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:30:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:23 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:30:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893506,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.828184,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 30, 23, 884527),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75292672,
 'memusage/startup': 75292672,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 30, 22, 56343)}
2019-11-28 09:30:23 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:30:47 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:30:47 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:30:47 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:30:47 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:30:48 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:30:48 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:30:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:30:48 [scrapy.extensions.telnet] INFO: Telnet Password: 758670937898143f
2019-11-28 09:30:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:30:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:30:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:30:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:30:48 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:30:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:30:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:30:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:30:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:30:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:30:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:30:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 895070,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.877039,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 30, 50, 739887),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75247616,
 'memusage/startup': 75247616,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 30, 48, 862848)}
2019-11-28 09:30:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:34:39 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:34:39 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:34:39 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:34:39 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:34:40 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:34:40 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:34:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:34:40 [scrapy.extensions.telnet] INFO: Telnet Password: 8fd916b37715a9ff
2019-11-28 09:34:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:34:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:34:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:34:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:34:40 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:34:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:34:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:34:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:34:42 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:34:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893538,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.855142,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 34, 42, 799865),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75218944,
 'memusage/startup': 75218944,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 34, 40, 944723)}
2019-11-28 09:34:42 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:35:00 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:35:00 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:35:00 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:35:00 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:35:01 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:35:01 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:35:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:35:01 [scrapy.extensions.telnet] INFO: Telnet Password: 87be4bf792a5f8f1
2019-11-28 09:35:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:35:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:35:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:35:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:35:02 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:35:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:35:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:35:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:35:03 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:35:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893861,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.848674,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 35, 3, 925364),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75063296,
 'memusage/startup': 75063296,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 35, 2, 76690)}
2019-11-28 09:35:03 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:37:25 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:37:25 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:37:25 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:37:25 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:37:27 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:37:27 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:37:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:37:27 [scrapy.extensions.telnet] INFO: Telnet Password: fd22fc9793554617
2019-11-28 09:37:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:37:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:37:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:37:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:37:27 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:37:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:37:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:37:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:37:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:37:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:29 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:37:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893775,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.103203,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 37, 29, 964074),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 74956800,
 'memusage/startup': 74956800,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 37, 27, 860871)}
2019-11-28 09:37:29 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:37:42 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:37:42 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:37:42 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:37:42 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:37:44 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:37:44 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:37:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:37:44 [scrapy.extensions.telnet] INFO: Telnet Password: 2ddcd4feaf807bbd
2019-11-28 09:37:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:37:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:37:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:37:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:37:44 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:37:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:37:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:37:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:37:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:37:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894908,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.029565,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 37, 46, 547387),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75124736,
 'memusage/startup': 75124736,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 37, 44, 517822)}
2019-11-28 09:37:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:38:11 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:38:11 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:38:11 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:38:11 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:38:13 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:38:13 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:38:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:38:13 [scrapy.extensions.telnet] INFO: Telnet Password: bdfc800113224ec6
2019-11-28 09:38:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:38:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:38:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:38:13 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:38:13 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:38:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:38:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:38:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:38:15 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:38:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893464,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.864061,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 38, 15, 388497),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75202560,
 'memusage/startup': 75202560,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 38, 13, 524436)}
2019-11-28 09:38:15 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:38:58 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:38:58 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:38:58 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:38:58 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:38:59 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:38:59 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:38:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:38:59 [scrapy.extensions.telnet] INFO: Telnet Password: 6043aa0bcf1f5a1a
2019-11-28 09:38:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:38:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:38:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:38:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:38:59 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:38:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:38:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:39:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:39:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:39:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:39:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:39:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893410,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.940695,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 39, 1, 889914),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75100160,
 'memusage/startup': 75100160,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 38, 59, 949219)}
2019-11-28 09:39:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:43:57 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:43:57 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:43:57 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:43:57 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:43:58 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:43:58 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:43:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:43:58 [scrapy.extensions.telnet] INFO: Telnet Password: 77e4907c7002a647
2019-11-28 09:43:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:43:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:43:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:43:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:43:58 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:43:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:43:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:43:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:43:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:44:00 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:44:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894527,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.975434,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 44, 0, 757345),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75005952,
 'memusage/startup': 75005952,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 43, 58, 781911)}
2019-11-28 09:44:00 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:44:59 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:44:59 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:44:59 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:44:59 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:45:00 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:45:00 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:45:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:45:00 [scrapy.extensions.telnet] INFO: Telnet Password: c3a6a0904d5c1c52
2019-11-28 09:45:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:45:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:45:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:45:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:45:00 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:45:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:45:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:45:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:02 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:45:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893584,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.69664,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 45, 2, 358108),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75042816,
 'memusage/startup': 75042816,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 45, 0, 661468)}
2019-11-28 09:45:02 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:45:19 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:45:19 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:45:19 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:45:19 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:45:20 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:45:20 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:45:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:45:20 [scrapy.extensions.telnet] INFO: Telnet Password: 21784476b822cfd6
2019-11-28 09:45:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:45:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:45:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:45:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:45:20 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:45:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:45:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:45:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:45:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:45:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:45:22 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:45:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894740,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.786802,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 45, 22, 785058),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75128832,
 'memusage/startup': 75128832,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 45, 20, 998256)}
2019-11-28 09:45:22 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:46:47 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:46:47 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:46:47 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:46:47 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:46:49 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:46:49 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:46:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:46:49 [scrapy.extensions.telnet] INFO: Telnet Password: f981ac03252d29b3
2019-11-28 09:46:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:46:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:46:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:46:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:46:49 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:46:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:46:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:46:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:46:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:46:50 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:46:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894215,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.772689,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 46, 50, 872528),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75214848,
 'memusage/startup': 75214848,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 46, 49, 99839)}
2019-11-28 09:46:50 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:47:51 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:47:51 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:47:51 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:47:51 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:47:53 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:47:53 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:47:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:47:53 [scrapy.extensions.telnet] INFO: Telnet Password: 2cd9504b8ab7aed5
2019-11-28 09:47:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:47:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:47:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:47:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:47:53 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:47:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:47:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:47:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:47:55 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:47:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893665,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.734707,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 47, 55, 130610),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75014144,
 'memusage/startup': 75014144,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 47, 53, 395903)}
2019-11-28 09:47:55 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:48:15 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:48:15 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:48:15 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:48:15 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:48:17 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:48:17 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:48:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:48:17 [scrapy.extensions.telnet] INFO: Telnet Password: 8f16a0da65fac773
2019-11-28 09:48:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:48:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:48:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:48:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:48:17 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:48:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:48:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:48:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:48:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:48:18 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:48:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893893,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.705069,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 48, 18, 845155),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75272192,
 'memusage/startup': 75272192,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 48, 17, 140086)}
2019-11-28 09:48:18 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:49:04 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:49:04 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:49:04 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:49:04 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:49:05 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:49:05 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:49:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:49:05 [scrapy.extensions.telnet] INFO: Telnet Password: 6a66b7ef18cddbc3
2019-11-28 09:49:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:49:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:49:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:49:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:49:05 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:49:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:49:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:49:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:49:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:07 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:49:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894008,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.862982,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 49, 7, 256330),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 74862592,
 'memusage/startup': 74862592,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 49, 5, 393348)}
2019-11-28 09:49:07 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:49:34 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:49:34 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:49:34 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:49:34 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:49:35 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:49:35 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:49:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:49:35 [scrapy.extensions.telnet] INFO: Telnet Password: cabcf78e72beb8df
2019-11-28 09:49:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:49:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:49:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:49:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:49:35 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:49:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:49:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:49:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:49:37 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:49:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893948,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.846682,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 49, 37, 382968),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 74969088,
 'memusage/startup': 74969088,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 49, 35, 536286)}
2019-11-28 09:49:37 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:56:14 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:56:14 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:56:14 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:56:14 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:56:15 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:56:15 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:56:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:56:15 [scrapy.extensions.telnet] INFO: Telnet Password: 7219534299428532
2019-11-28 09:56:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:56:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:56:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:56:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:56:16 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:56:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:56:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:56:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:56:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/spiders/hhru.py", line 24, in vacancy_parse
    location = response.xpath('//div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()').extract()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/http/response/text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/parsel/selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //div[@class="vacancy-company-wrapper"/span[@data-qa="vacancy-view-raw-address"][1]/text()
2019-11-28 09:56:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:56:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893625,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.942375,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 56, 17, 958816),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 75313152,
 'memusage/startup': 75313152,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'spider_exceptions/ValueError': 20,
 'start_time': datetime.datetime(2019, 11, 28, 6, 56, 16, 16441)}
2019-11-28 09:56:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 09:58:21 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 09:58:21 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 09:58:21 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 09:58:21 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 09:58:23 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 09:58:23 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 09:58:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 09:58:23 [scrapy.extensions.telnet] INFO: Telnet Password: ab6fe4384f356b0b
2019-11-28 09:58:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 09:58:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 09:58:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 09:58:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 09:58:23 [scrapy.core.engine] INFO: Spider opened
2019-11-28 09:58:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 09:58:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 09:58:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 09:58:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 09:58:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 09:58:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894604,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.973283,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 6, 58, 25, 105326),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 74870784,
 'memusage/startup': 74870784,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 6, 58, 23, 132043)}
2019-11-28 09:58:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 10:03:45 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 10:03:45 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 10:03:45 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 10:03:45 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 10:03:46 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 10:03:46 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 10:03:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 10:03:46 [scrapy.extensions.telnet] INFO: Telnet Password: 1e28f3c888798a68
2019-11-28 10:03:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 10:03:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 10:03:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 10:03:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 10:03:46 [scrapy.core.engine] INFO: Spider opened
2019-11-28 10:03:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 10:03:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 10:03:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 10:03:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 10:03:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:03:48 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 10:03:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894513,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.852768,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 7, 3, 48, 625669),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75026432,
 'memusage/startup': 75026432,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 7, 3, 46, 772901)}
2019-11-28 10:03:48 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 10:06:40 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 10:06:40 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 10:06:40 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 10:06:40 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 10:06:41 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 10:06:41 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 10:06:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 10:06:41 [scrapy.extensions.telnet] INFO: Telnet Password: cf1249e010d1e946
2019-11-28 10:06:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 10:06:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 10:06:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 10:06:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 10:06:41 [scrapy.core.engine] INFO: Spider opened
2019-11-28 10:06:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 10:06:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 10:06:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:06:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 10:06:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893573,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.83446,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 7, 6, 43, 333784),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75186176,
 'memusage/startup': 75186176,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 7, 6, 41, 499324)}
2019-11-28 10:06:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 10:10:13 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 10:10:13 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 10:10:13 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 10:10:13 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 10:10:14 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 10:10:14 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 10:10:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 10:10:14 [scrapy.extensions.telnet] INFO: Telnet Password: b3fd977eb173cc60
2019-11-28 10:10:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 10:10:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 10:10:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 10:10:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 10:10:14 [scrapy.core.engine] INFO: Spider opened
2019-11-28 10:10:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 10:10:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 10:10:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:10:16 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 10:10:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894255,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.94324,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 7, 10, 16, 351675),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75022336,
 'memusage/startup': 75022336,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 7, 10, 14, 408435)}
2019-11-28 10:10:16 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 10:15:57 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 10:15:57 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 10:15:57 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 10:15:57 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 10:15:59 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 10:15:59 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 10:15:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 10:15:59 [scrapy.extensions.telnet] INFO: Telnet Password: 9c8aac29d01e2cdc
2019-11-28 10:15:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 10:15:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 10:15:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 10:15:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 10:15:59 [scrapy.core.engine] INFO: Spider opened
2019-11-28 10:15:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 10:15:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 10:15:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 10:15:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:16:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 10:16:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894488,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.831886,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 7, 16, 1, 169563),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75116544,
 'memusage/startup': 75116544,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 7, 15, 59, 337677)}
2019-11-28 10:16:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 10:26:24 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 10:26:24 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 10:26:24 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 10:26:24 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 10:26:25 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 10:26:25 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 10:26:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 10:26:25 [scrapy.extensions.telnet] INFO: Telnet Password: 27804b6aa500337d
2019-11-28 10:26:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 10:26:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 10:26:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 10:26:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 10:26:25 [scrapy.core.engine] INFO: Spider opened
2019-11-28 10:26:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 10:26:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 10:26:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:26:27 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 10:26:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 893565,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.868717,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 7, 26, 27, 288617),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 74780672,
 'memusage/startup': 74780672,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 7, 26, 25, 419900)}
2019-11-28 10:26:27 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 10:31:29 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 10:31:29 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 10:31:29 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 10:31:29 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 10:31:30 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 10:31:30 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 10:31:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 10:31:30 [scrapy.extensions.telnet] INFO: Telnet Password: 7a3fc622c284d4c5
2019-11-28 10:31:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 10:31:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 10:31:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 10:31:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2019-11-28 10:31:31 [scrapy.core.engine] INFO: Spider opened
2019-11-28 10:31:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 10:31:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 10:31:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 10:31:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34510621?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 10:31:32 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 10:31:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 894549,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.949867,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 7, 31, 32, 988481),
 'log_count/DEBUG': 22,
 'log_count/INFO': 10,
 'memusage/max': 75087872,
 'memusage/startup': 75087872,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 7, 31, 31, 38614)}
2019-11-28 10:31:32 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:31:37 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:31:37 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:31:37 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:31:37 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:31:38 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:31:38 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:31:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:31:38 [scrapy.extensions.telnet] INFO: Telnet Password: 9eb328bf4792cea7
2019-11-28 11:31:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:31:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:31:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:31:38 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:31:38 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:31:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:31:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:31:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:31:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:31:40 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:31:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898561,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.74068,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 31, 40, 677439),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79425536,
 'memusage/startup': 79425536,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 31, 38, 936759)}
2019-11-28 11:31:40 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:33:52 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:33:52 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:33:52 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:33:52 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:33:53 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:33:53 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:33:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:33:53 [scrapy.extensions.telnet] INFO: Telnet Password: a2ce90a86e335612
2019-11-28 11:33:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:33:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:33:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:33:53 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:33:53 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:33:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:33:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:33:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:54 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    self.mongo_db[spider.name].insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:33:55 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:33:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898599,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.837338,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 33, 55, 434826),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79405056,
 'memusage/startup': 79405056,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 33, 53, 597488)}
2019-11-28 11:33:55 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:40:14 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:40:14 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:40:14 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:40:14 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:40:15 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:40:15 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:40:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:40:15 [scrapy.extensions.telnet] INFO: Telnet Password: 3b7d6f81b9490182
2019-11-28 11:40:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:40:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:40:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:41:42 [twisted] CRITICAL: Unhandled error in Deferred:
2019-11-28 11:41:42 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 86, in crawl
    self.engine = self._create_engine()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 111, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/utils/misc.py", line 46, in load_object
    mod = import_module(module)
  File "/home/nikola4725/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15
    self.mongo_db.'hhru'.insert_one(item)
                       ^
SyntaxError: invalid syntax
2019-11-28 11:41:42 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:41:42 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:41:42 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:41:42 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:41:43 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:41:43 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:41:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:41:43 [scrapy.extensions.telnet] INFO: Telnet Password: eb287445c32a0bb0
2019-11-28 11:41:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:41:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:41:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:41:43 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:41:43 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:41:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:41:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:41:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:44 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:41:45 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:41:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 899484,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.755273,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 41, 45, 571624),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79511552,
 'memusage/startup': 79511552,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 41, 43, 816351)}
2019-11-28 11:41:45 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:42:14 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:42:14 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:42:14 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:42:14 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:42:15 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:42:15 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:42:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:42:15 [scrapy.extensions.telnet] INFO: Telnet Password: ac8d65c2f632e160
2019-11-28 11:42:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:42:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:42:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:42:15 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:42:15 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:42:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:42:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:42:15 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:42:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:42:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:16 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:42:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:42:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898289,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.731873,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 42, 17, 564508),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79421440,
 'memusage/startup': 79421440,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 42, 15, 832635)}
2019-11-28 11:42:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:44:55 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:44:55 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:44:55 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:44:55 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:44:56 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:44:56 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:44:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:44:56 [scrapy.extensions.telnet] INFO: Telnet Password: 943739fc6c5bc9c2
2019-11-28 11:44:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:44:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:44:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:44:56 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:44:56 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:44:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:44:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:44:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:44:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    print(col)
NameError: name 'col' is not defined
2019-11-28 11:44:58 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:44:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898564,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.951258,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 44, 58, 906190),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79536128,
 'memusage/startup': 79536128,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 44, 56, 954932)}
2019-11-28 11:44:58 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:45:36 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:45:36 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:45:36 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:45:36 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:45:37 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:45:37 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:45:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:45:37 [scrapy.extensions.telnet] INFO: Telnet Password: 90ab77da8b2a9402
2019-11-28 11:45:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:45:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:45:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:45:37 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:45:37 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:45:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:45:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:45:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:45:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:38 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:45:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:45:39 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:45:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 899370,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.801674,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 45, 39, 184965),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79327232,
 'memusage/startup': 79327232,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 45, 37, 383291)}
2019-11-28 11:45:39 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:47:06 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:47:06 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:47:06 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:47:06 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:47:07 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:47:07 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:47:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:47:07 [scrapy.extensions.telnet] INFO: Telnet Password: 3aa565391bdaf071
2019-11-28 11:47:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:47:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:47:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:47:08 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:47:08 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:47:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:47:08 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:47:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:47:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    coll.insert_one(item)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/pymongo/collection.py", line 691, in insert_one
    document["_id"] = ObjectId()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'JobparserItem does not support field: _id'
2019-11-28 11:47:09 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:47:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898134,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.807363,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 47, 9, 817745),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79253504,
 'memusage/startup': 79253504,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 47, 8, 10382)}
2019-11-28 11:47:09 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:51:32 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:51:32 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:51:32 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:51:32 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:51:34 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:51:34 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:51:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:51:34 [scrapy.extensions.telnet] INFO: Telnet Password: 70bcae9c824faf8f
2019-11-28 11:51:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:51:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:51:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:51:34 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:51:34 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:51:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:51:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:51:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:51:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34029220?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e321'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34559009?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e322'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34381392?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e323'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34748563?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e324'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34200113?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e325'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34669711?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e326'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33864288?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e327'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34418956?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e328'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/31917536?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e329'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775001?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e32a'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33563753?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e32b'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33070488?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e32c'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33774758?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e32d'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/32231894?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e32e'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34432731?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e32f'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34746892?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e330'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33075021?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e331'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33204430?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e332'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
2019-11-28 11:51:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775102?query=python>
{'_id': ObjectId('5ddf8a97f866398d3190e333'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
2019-11-28 11:51:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34704357?query=python>
{'_id': ObjectId('5ddf8a98f866398d3190e334'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
2019-11-28 11:51:36 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:51:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898073,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.729345,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 51, 36, 4182),
 'item_scraped_count': 20,
 'log_count/DEBUG': 42,
 'log_count/INFO': 10,
 'memusage/max': 79597568,
 'memusage/startup': 79597568,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 51, 34, 274837)}
2019-11-28 11:51:36 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:54:59 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:54:59 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:54:59 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:54:59 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:55:00 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:55:00 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:55:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:55:00 [scrapy.extensions.telnet] INFO: Telnet Password: de79cae1ba39e905
2019-11-28 11:55:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:55:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:55:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:55:00 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:55:00 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:55:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:55:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:55:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:02 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:02 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:55:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898603,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.81545,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 55, 2, 328064),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79540224,
 'memusage/startup': 79540224,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 55, 0, 512614)}
2019-11-28 11:55:02 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:55:42 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:55:42 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:55:42 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:55:42 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:55:43 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:55:43 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:55:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:55:43 [scrapy.extensions.telnet] INFO: Telnet Password: b04f3cfcd4c77ec0
2019-11-28 11:55:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:55:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:55:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:55:43 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:55:43 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:55:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:55:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:55:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:55:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:55:46 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:55:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:55:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898499,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.03364,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 55, 46, 12827),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79212544,
 'memusage/startup': 79212544,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 55, 43, 979187)}
2019-11-28 11:55:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:57:03 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:57:03 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:57:03 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:57:03 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:57:04 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:57:04 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:57:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:57:04 [scrapy.extensions.telnet] INFO: Telnet Password: 8e18992916dd8906
2019-11-28 11:57:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:57:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:57:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:57:05 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:57:05 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:57:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:57:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:57:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:57:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 17, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:57:06 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:57:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898535,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.816387,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 57, 6, 861945),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79421440,
 'memusage/startup': 79421440,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 57, 5, 45558)}
2019-11-28 11:57:06 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:58:36 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:58:36 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:58:36 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:58:36 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:58:38 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:58:38 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:58:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:58:38 [scrapy.extensions.telnet] INFO: Telnet Password: 4e75da83074d8dea
2019-11-28 11:58:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:58:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:58:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:58:38 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:58:38 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:58:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:58:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:58:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:58:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:58:39 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:58:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 899559,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.73021,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 58, 39, 877987),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79392768,
 'memusage/startup': 79392768,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 58, 38, 147777)}
2019-11-28 11:58:39 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 11:59:07 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 11:59:07 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 11:59:07 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 11:59:07 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 11:59:08 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 11:59:08 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 11:59:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 11:59:08 [scrapy.extensions.telnet] INFO: Telnet Password: 24db9df799aacd3b
2019-11-28 11:59:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 11:59:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 11:59:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 11:59:09 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 11:59:09 [scrapy.core.engine] INFO: Spider opened
2019-11-28 11:59:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 11:59:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 11:59:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 11:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 11:59:10 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 11:59:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898930,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.753545,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 8, 59, 10, 885789),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79347712,
 'memusage/startup': 79347712,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 8, 59, 9, 132244)}
2019-11-28 11:59:10 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:00:52 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:00:52 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:00:52 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:00:52 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:00:54 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:00:54 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:00:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:00:54 [scrapy.extensions.telnet] INFO: Telnet Password: 6f24e042666094e8
2019-11-28 12:00:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:00:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:00:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:02:32 [twisted] CRITICAL: Unhandled error in Deferred:
2019-11-28 12:02:32 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 86, in crawl
    self.engine = self._create_engine()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 111, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/utils/misc.py", line 46, in load_object
    mod = import_module(module)
  File "/home/nikola4725/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 18
    collection = self.mongo_db.'hhru'
                                    ^
SyntaxError: invalid syntax
2019-11-28 12:02:32 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:02:32 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:02:32 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:02:32 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:02:34 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:02:34 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:02:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:02:34 [scrapy.extensions.telnet] INFO: Telnet Password: 9b16b95a91b164da
2019-11-28 12:02:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:02:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:02:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:03:22 [twisted] CRITICAL: Unhandled error in Deferred:
2019-11-28 12:03:22 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 86, in crawl
    self.engine = self._create_engine()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 111, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/utils/misc.py", line 46, in load_object
    mod = import_module(module)
  File "/home/nikola4725/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 18
    collection = self.mongo_db.'hhru'
                                    ^
SyntaxError: invalid syntax
2019-11-28 12:03:22 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:03:22 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:03:22 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:03:22 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:03:23 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:03:23 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:03:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:03:23 [scrapy.extensions.telnet] INFO: Telnet Password: 39b56f86c26051cd
2019-11-28 12:03:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:03:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:03:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:03:23 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:03:23 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:03:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:03:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:03:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34029220?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c550'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34559009?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c551'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34748563?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c552'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34381392?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c553'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775001?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c554'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34669711?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c555'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34200113?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c556'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/31917536?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c557'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34418956?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c558'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
2019-11-28 12:03:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33563753?query=python>
{'_id': ObjectId('5ddf8d5c9b17ef2367b3c559'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33070488?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c55a'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33864288?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c55b'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/32231894?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c55c'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33075021?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c55d'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33774758?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c55e'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34432731?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c55f'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775102?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c560'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34704357?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c561'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34746892?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c562'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33204430?query=python>
{'_id': ObjectId('5ddf8d5d9b17ef2367b3c563'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
2019-11-28 12:03:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:03:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 897922,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.87057,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 3, 25, 324388),
 'item_scraped_count': 20,
 'log_count/DEBUG': 42,
 'log_count/INFO': 10,
 'memusage/max': 79314944,
 'memusage/startup': 79314944,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 3, 23, 453818)}
2019-11-28 12:03:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:03:57 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:03:57 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:03:57 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:03:57 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:03:58 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:03:58 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:03:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:03:58 [scrapy.extensions.telnet] INFO: Telnet Password: 01aa25f0b02d9180
2019-11-28 12:03:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:03:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:03:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:03:58 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:03:58 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:03:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:03:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:03:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34029220?query=python>
{'_id': ObjectId('5ddf8d7f3d0e6ebdaab45877'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34381392?query=python>
{'_id': ObjectId('5ddf8d7f3d0e6ebdaab45878'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34200113?query=python>
{'_id': ObjectId('5ddf8d7f3d0e6ebdaab45879'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
2019-11-28 12:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33864288?query=python>
{'_id': ObjectId('5ddf8d7f3d0e6ebdaab4587a'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
2019-11-28 12:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34559009?query=python>
{'_id': ObjectId('5ddf8d7f3d0e6ebdaab4587b'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
2019-11-28 12:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34669711?query=python>
{'_id': ObjectId('5ddf8d7f3d0e6ebdaab4587c'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
2019-11-28 12:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34748563?query=python>
{'_id': ObjectId('5ddf8d7f3d0e6ebdaab4587d'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
2019-11-28 12:03:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775001?query=python>
{'_id': ObjectId('5ddf8d7f3d0e6ebdaab4587e'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:03:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/31917536?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab4587f'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34418956?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45880'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33563753?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45881'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33774758?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45882'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34432731?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45883'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/32231894?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45884'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33070488?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45885'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34746892?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45886'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33075021?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45887'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775102?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45888'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33204430?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab45889'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34704357?query=python>
{'_id': ObjectId('5ddf8d803d0e6ebdaab4588a'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
2019-11-28 12:04:00 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:04:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898079,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.813556,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 4, 0, 344929),
 'item_scraped_count': 20,
 'log_count/DEBUG': 42,
 'log_count/INFO': 10,
 'memusage/max': 79405056,
 'memusage/startup': 79405056,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 3, 58, 531373)}
2019-11-28 12:04:00 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:04:31 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:04:31 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:04:31 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:04:31 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:04:32 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:04:32 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:04:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:04:32 [scrapy.extensions.telnet] INFO: Telnet Password: c7918a78d45155c3
2019-11-28 12:04:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:04:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:04:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:04:32 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:04:32 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:04:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:04:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:04:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:04:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:04:34 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:04:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 899494,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.878076,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 4, 34, 431113),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79405056,
 'memusage/startup': 79405056,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 4, 32, 553037)}
2019-11-28 12:04:34 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:06:33 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:06:33 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:06:33 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:06:33 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:06:34 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:06:34 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:06:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:06:34 [scrapy.extensions.telnet] INFO: Telnet Password: d87cb569a3cc095d
2019-11-28 12:06:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:06:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:06:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:06:34 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:06:34 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:06:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:06:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:06:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34559009?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:35 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34559009?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': '   ,     A / '
         'iFuture',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:35 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:35 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:35 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:35 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 16, in process_item
    item.min_salary = int(item.min_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:06:36 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:06:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 898009,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.735244,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 6, 36, 376788),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79515648,
 'memusage/startup': 79515648,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 6, 34, 641544)}
2019-11-28 12:06:36 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:08:03 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:08:03 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:08:03 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:08:03 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:08:04 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:08:04 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:08:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:08:04 [scrapy.extensions.telnet] INFO: Telnet Password: 5523757d00d644b9
2019-11-28 12:08:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:08:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:08:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:08:04 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:08:04 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:08:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:08:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:08:04 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:05 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 21, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:08:06 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:08:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 905477,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.805257,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 8, 6, 572026),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79302656,
 'memusage/startup': 79302656,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 8, 4, 766769)}
2019-11-28 12:08:06 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:08:53 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:08:53 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:08:53 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:08:53 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:08:55 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:08:55 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:08:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:08:55 [scrapy.extensions.telnet] INFO: Telnet Password: 87ece0a2bd8a8dfc
2019-11-28 12:08:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:08:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:08:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:09:15 [twisted] CRITICAL: Unhandled error in Deferred:
2019-11-28 12:09:15 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 86, in crawl
    self.engine = self._create_engine()
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/crawler.py", line 111, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/utils/misc.py", line 46, in load_object
    mod = import_module(module)
  File "/home/nikola4725/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15
    print spider.name
               ^
SyntaxError: Missing parentheses in call to 'print'. Did you mean print(spider.name)?
2019-11-28 12:09:15 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:09:15 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:09:15 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:09:15 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:09:16 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:09:16 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:09:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:09:16 [scrapy.extensions.telnet] INFO: Telnet Password: 6202b2fd8df34ae1
2019-11-28 12:09:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:09:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:09:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:09:16 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:09:16 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:09:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:09:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:09:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:18 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:09:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 904704,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.777342,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 9, 18, 719785),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79753216,
 'memusage/startup': 79753216,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 9, 16, 942443)}
2019-11-28 12:09:18 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:09:43 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:09:43 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:09:43 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:09:43 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:09:44 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:09:44 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:09:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:09:44 [scrapy.extensions.telnet] INFO: Telnet Password: acda744651da4c52
2019-11-28 12:09:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:09:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:09:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:09:44 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:09:44 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:09:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:09:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:09:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:45 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:46 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:09:46 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:09:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:09:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 905621,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.767813,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 9, 46, 251485),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79601664,
 'memusage/startup': 79601664,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 9, 44, 483672)}
2019-11-28 12:09:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:10:13 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:10:13 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:10:13 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:10:13 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:10:14 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:10:14 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:10:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:10:14 [scrapy.extensions.telnet] INFO: Telnet Password: 2bb2ead896ec2255
2019-11-28 12:10:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:10:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:10:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:10:14 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:10:14 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:10:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:10:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:10:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:15 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:16 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:16 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:16 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:16 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:16 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:16 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:16 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:16 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:10:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 904513,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.814044,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 10, 16, 225427),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79454208,
 'memusage/startup': 79454208,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 10, 14, 411383)}
2019-11-28 12:10:16 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:10:54 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:10:54 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:10:54 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:10:54 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:10:55 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:10:55 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:10:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:10:55 [scrapy.extensions.telnet] INFO: Telnet Password: 8d5f4eaaad140a87
2019-11-28 12:10:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:10:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:10:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:10:55 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:10:55 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:10:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:10:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:10:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:56 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:57 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:10:57 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:57 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:57 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:57 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:57 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item_max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:10:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:10:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 905724,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.743636,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 10, 57, 128861),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79368192,
 'memusage/startup': 79368192,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 10, 55, 385225)}
2019-11-28 12:10:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:11:27 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:11:27 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:11:27 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:11:27 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:11:28 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:11:28 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:11:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:11:28 [scrapy.extensions.telnet] INFO: Telnet Password: 8fa2ffd6424b73f9
2019-11-28 12:11:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:11:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:11:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:11:28 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:11:28 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:11:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:11:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:11:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:30 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 15, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:30 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:11:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 904392,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.935946,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 11, 30, 372650),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79196160,
 'memusage/startup': 79196160,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 11, 28, 436704)}
2019-11-28 12:11:30 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:11:55 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:11:55 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:11:55 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:11:55 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:11:56 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:11:56 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:11:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:11:56 [scrapy.extensions.telnet] INFO: Telnet Password: 3223275d0f5a47b8
2019-11-28 12:11:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:11:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:11:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:11:56 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:11:56 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:11:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:11:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:11:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:58 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:58 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:11:59 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:00 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:00 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:00 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:00 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:00 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:12:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 906243,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.804363,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 12, 0, 649943),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79544320,
 'memusage/startup': 79544320,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 11, 56, 845580)}
2019-11-28 12:12:00 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:12:30 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:12:30 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:12:30 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:12:30 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:12:32 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:12:32 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:12:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:12:32 [scrapy.extensions.telnet] INFO: Telnet Password: d8d25046b1ffd587
2019-11-28 12:12:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:12:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:12:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:12:32 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:12:32 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:12:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:12:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:12:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 23, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:12:34 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:12:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 905268,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.97401,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 12, 34, 262844),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79654912,
 'memusage/startup': 79654912,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 12, 32, 288834)}
2019-11-28 12:12:34 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:13:14 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:13:14 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:13:14 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:13:14 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:13:15 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:13:15 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:13:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:13:15 [scrapy.extensions.telnet] INFO: Telnet Password: 5b81cf6eeb0f8b51
2019-11-28 12:13:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:13:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:13:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:13:15 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:13:15 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:13:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:13:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:13:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': '170000',
 'min_salary': '140000',
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': '120000',
 'min_salary': '60000',
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': '180000',
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': '200000',
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': '2200',
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': '5000',
 'min_salary': '3500',
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:13:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:18 [scrapy.core.scraper] ERROR: Error processing {'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': '230000',
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': '100000',
 'min_salary': '40000',
 'name': '   ,   24',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:18 [scrapy.core.scraper] ERROR: Error processing {'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': '170000',
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
Traceback (most recent call last):
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/nikola4725/lesson_05/jobparser/pipelines.py", line 22, in process_item
    print(spider.name, item.min_salary, item.max_salary)
  File "/home/nikola4725/anaconda3/lib/python3.7/site-packages/scrapy/item.py", line 105, in __getattr__
    raise AttributeError("Use item[%r] to get field value" % name)
AttributeError: Use item['min_salary'] to get field value
2019-11-28 12:13:18 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:13:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 906230,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 2.42018,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 13, 18, 183441),
 'log_count/DEBUG': 22,
 'log_count/ERROR': 20,
 'log_count/INFO': 10,
 'memusage/max': 79589376,
 'memusage/startup': 79589376,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 13, 15, 763261)}
2019-11-28 12:13:18 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:14:38 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:14:38 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:14:38 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:14:38 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:14:40 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:14:40 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:14:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:14:40 [scrapy.extensions.telnet] INFO: Telnet Password: 36250854b045b2c5
2019-11-28 12:14:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:14:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:14:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:14:40 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:14:40 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:14:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:14:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:14:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:14:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34029220?query=python>
{'_id': ObjectId('5ddf9002861921dfc7831e2a'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': 170000,
 'min_salary': 140000,
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
2019-11-28 12:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34748563?query=python>
{'_id': ObjectId('5ddf9002861921dfc7831e2b'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': 2200,
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
2019-11-28 12:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34418956?query=python>
{'_id': ObjectId('5ddf9002861921dfc7831e2c'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
2019-11-28 12:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34669711?query=python>
{'_id': ObjectId('5ddf9002861921dfc7831e2d'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
2019-11-28 12:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33563753?query=python>
{'_id': ObjectId('5ddf9002861921dfc7831e2e'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33864288?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e2f'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/31917536?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e30'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': 180000,
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775001?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e31'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': 120000,
 'min_salary': 60000,
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34381392?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e32'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34200113?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e33'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': 200000,
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33774758?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e34'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34432731?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e35'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33070488?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e36'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34746892?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e37'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': 230000,
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33075021?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e38'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': 5000,
 'min_salary': 3500,
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/32231894?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e39'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33204430?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e3a'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': 170000,
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34704357?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e3b'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775102?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e3c'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': 100000,
 'min_salary': 40000,
 'name': '   ,   24',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33206558?query=python>
{'_id': ObjectId('5ddf9003861921dfc7831e3d'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
2019-11-28 12:14:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:14:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 904472,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 3.284393,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 14, 43, 621570),
 'item_scraped_count': 20,
 'log_count/DEBUG': 42,
 'log_count/INFO': 10,
 'memusage/max': 79482880,
 'memusage/startup': 79482880,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 14, 40, 337177)}
2019-11-28 12:14:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:15:42 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:15:42 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:15:42 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:15:42 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
2019-11-28 12:15:44 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: jobparser)
2019-11-28 12:15:44 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.3 (default, Mar 27 2019, 22:11:17) - [GCC 7.3.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-5.0.0-36-generic-x86_64-with-debian-buster-sid
2019-11-28 12:15:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'jobparser', 'LOG_FILE': 'jobparser_log.txt', 'NEWSPIDER_MODULE': 'jobparser.spiders', 'SPIDER_MODULES': ['jobparser.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'}
2019-11-28 12:15:44 [scrapy.extensions.telnet] INFO: Telnet Password: ff048e81d7d664c9
2019-11-28 12:15:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-11-28 12:15:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-11-28 12:15:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-11-28 12:15:44 [scrapy.middleware] INFO: Enabled item pipelines:
['jobparser.pipelines.JobparserPipeline']
2019-11-28 12:15:44 [scrapy.core.engine] INFO: Spider opened
2019-11-28 12:15:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-11-28 12:15:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-11-28 12:15:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> from <GET https://hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true>
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true> (referer: None)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34029220?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33864288?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/31917536?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775001?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34200113?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34748563?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34381392?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34029220?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba00'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34029220?query=python',
 'max_salary': 170000,
 'min_salary': 140000,
 'name': ' Data scientist (ML , python)  ,   '
         'Mindbox',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34669711?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33864288?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba01'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33864288?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Data Analyst (Senior)  ,     '
         '',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/31917536?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba02'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/31917536?query=python',
 'max_salary': None,
 'min_salary': 180000,
 'name': ' Senior C++ Developer (Videostreaming)  -, '
         '    ',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775001?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba03'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775001?query=python',
 'max_salary': 120000,
 'min_salary': 60000,
 'name': ' ++ Software Developer ( ++)  , '
         '  ',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33563753?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34418956?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34200113?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba04'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34200113?query=python',
 'max_salary': None,
 'min_salary': 200000,
 'name': '   Python / Software development / Team '
         'lead  ,   CATAPULTO.RU',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34748563?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba05'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/34748563?query=python',
 'max_salary': None,
 'min_salary': 2200,
 'name': ' C++ developer Middle lvl ( ++)  ,  '
         ' ',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34432731?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34381392?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba06'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34381392?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' C++ Developer  ,       '
         ' ',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33774758?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33075021?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34669711?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba07'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34669711?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Product owner ( face recognition)  '
         '-,    |  ',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/32231894?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33563753?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba08'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33563753?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' DevOps/Linux-  ,   ',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34418956?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba09'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34418956?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Backend- (PHP/Symfony)  ,   Like '
         '',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34432731?query=python>
{'_id': ObjectId('5ddf9041179aac3431d5ba0a'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34432731?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Embedded DevOps/ Developer  ,   SaM Solutions '
         '',
 'site': 'hh.ru'}
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33070488?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34704357?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34746892?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33774758?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba0b'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33774758?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior data engineer ( )  ,   '
         '  ',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33075021?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba0c'),
 'curr': 'USD',
 'link': 'https://stary-oskol.hh.ru/vacancy/33075021?query=python',
 'max_salary': 5000,
 'min_salary': 3500,
 'name': ' Senior DevOps Engineer  ,   SoftSwiss',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/32231894?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba0d'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/32231894?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Junior Software Developer  ,   Profitero',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/34775102?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33070488?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba0e'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33070488?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Scala Developer (Java / C++ / # / Python)  ,  '
         ' NAUMEN',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34704357?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba0f'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/34704357?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Python Developer  ,    '
         '',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33204430?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34746892?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba10'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34746892?query=python',
 'max_salary': None,
 'min_salary': 230000,
 'name': ' Senior Frontend Developer (JavaScript, React)  , '
         '  HeadHunter::Frontend',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stary-oskol.hh.ru/vacancy/33206558?query=python> (referer: https://stary-oskol.hh.ru/search/vacancy?clusters=true&enable_snippets=true&text=python&showClusters=true)
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/34775102?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba11'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/34775102?query=python',
 'max_salary': 100000,
 'min_salary': 40000,
 'name': '   ,   24',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33204430?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba12'),
 'curr': 'RUR',
 'link': 'https://stary-oskol.hh.ru/vacancy/33204430?query=python',
 'max_salary': None,
 'min_salary': 170000,
 'name': ' Data Scientist  ,   JetBrains',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stary-oskol.hh.ru/vacancy/33206558?query=python>
{'_id': ObjectId('5ddf9042179aac3431d5ba13'),
 'curr': None,
 'link': 'https://stary-oskol.hh.ru/vacancy/33206558?query=python',
 'max_salary': None,
 'min_salary': None,
 'name': ' Senior Data Scientist ( )  -, '
         '    ',
 'site': 'hh.ru'}
2019-11-28 12:15:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-11-28 12:15:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 16009,
 'downloader/request_count': 22,
 'downloader/request_method_count/GET': 22,
 'downloader/response_bytes': 905899,
 'downloader/response_count': 22,
 'downloader/response_status_count/200': 21,
 'downloader/response_status_count/302': 1,
 'elapsed_time_seconds': 1.831231,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 11, 28, 9, 15, 46, 269213),
 'item_scraped_count': 20,
 'log_count/DEBUG': 42,
 'log_count/INFO': 10,
 'memusage/max': 79343616,
 'memusage/startup': 79343616,
 'request_depth_max': 1,
 'response_received_count': 21,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2019, 11, 28, 9, 15, 44, 437982)}
2019-11-28 12:15:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-11-28 12:15:50 [root] ERROR: Invalid alias: The name clear can't be aliased because it is another magic command.
2019-11-28 12:15:50 [root] ERROR: Invalid alias: The name more can't be aliased because it is another magic command.
2019-11-28 12:15:50 [root] ERROR: Invalid alias: The name less can't be aliased because it is another magic command.
2019-11-28 12:15:50 [root] ERROR: Invalid alias: The name man can't be aliased because it is another magic command.
