{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 2. Парсинг HTML. BeautifulSoup, MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы) с сайта superjob.ru и hh.ru. Приложение должно анализировать несколько страниц сайта(также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:\n",
    "\n",
    "    *Наименование вакансии\n",
    "    *Предлагаемую зарплату (отдельно мин. и отдельно макс.)\n",
    "    *Ссылку на саму вакансию        \n",
    "    *Сайт откуда собрана вакансия\n",
    "По своему желанию можно добавить еще работодателя и расположение. Данная структура должна быть одинаковая для вакансий с обоих сайтов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Парсинг HTML. BS, SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Развернуть у себя на компьютере/виртуальной машине/хостинге MongoDB и реализовать функцию, записывающую собранные вакансии в созданную БД  \n",
    "2) Написать функцию, которая производит поиск и выводит на экран вакансии с заработной платой больше введенной суммы  \n",
    "3)*Написать функцию, которая будет добавлять в вашу базу данных только новые вакансии с сайта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from pymongo import MongoClient\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = MongoClient('localhost',27017)\n",
    "db = db_client['hh_sj_scraping']\n",
    "mongo_hh = db.hh\n",
    "mongo_sj = db.sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "Chrome/78.0.3904.97 Safari/537.36'\n",
    "headers = {'User-Agent': user_agent}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Настройки для парсинга - ссылки, теги, атрибуты. чтобы все в одном месте "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_params = {'main_link' : 'https://hh.ru',\n",
    "            'search_link' : '/search/vacancy?text=',\n",
    "            'links_prefix' : '',\n",
    "            'links_tags' : ['a', 'div', 'script'],\n",
    "            'links_attrs' : [{'class':'bloko-link HH-LinkModifier'}, \n",
    "                             {'class':'resume-search-item__name'},\n",
    "                             {'data-name':'HH/AjaxContentLoader'}],\n",
    "            'vac_tot_tag' : 'a',\n",
    "            'vac_tot_attr' : {'class':'bloko-link HH-LinkModifier'},\n",
    "            'pages_tot_tag' : 'a',\n",
    "            'pages_tot_attr' : {'class':'bloko-button HH-Pager-Control'},\n",
    "            'vac_name_tag' : 'h1',\n",
    "            'vac_name_attrs' : {'data-qa':'vacancy-title'},\n",
    "            'vac_empl_tag' : 'span',\n",
    "            'vac_empl_attrs' : {'itemprop':'name'},\n",
    "            'vac_loc_tag' : 'span',\n",
    "            'vac_loc_attrs' : [{'data-qa':'vacancy-view-raw-address'}, {'itemprop':'jobLocation'}],\n",
    "            'vac_salary_tag' : 'meta',\n",
    "            'vac_salary_attrs' : [{'itemprop':'currency'}, {'itemprop':'minValue'}, {'itemprop':'maxValue'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_params = {'main_link' : 'https://www.superjob.ru',\n",
    "            'search_link' : '/vacancy/search/?geo%5Bc%5D%5B0%5D=1&keywords=',\n",
    "            'links_prefix' : 'https://www.superjob.ru',\n",
    "            'links_tags' : ['a', 'div'],\n",
    "            'links_attrs' : [{'target':'_blank'}, {'class':'_3syPg _3P0J7 _9_FPy'}],\n",
    "            'vac_tot_tag' : 'div',\n",
    "            'vac_tot_attr' : {'class':'_1tH7S _1o0Xp GPKTZ _3achh _3ofxL _2_FIo'},\n",
    "            'pages_tot_tag' : 'span',\n",
    "            'pages_tot_attr' : {'class':'qTHqo _2h9me DYJ1Y _2FQ5q _2GT-y'},\n",
    "            'vac_name_tag' : 'h1',\n",
    "            'vac_name_attrs' : {'class':'_3mfro rFbjy s1nFK _2JVkc'},\n",
    "            'vac_empl_tag' : 'h2',\n",
    "            'vac_empl_attrs' : {'class':'_3mfro PlM3e _2JVkc _2VHxz _3LJqf _15msI'},\n",
    "            'vac_loc_tag' : 'span',\n",
    "            'vac_loc_attrs' : [{'class':'_6-z9f'}],\n",
    "            'vac_salary_tag' : 'span',\n",
    "            'vac_salary_attrs' : {'class':'_3mfro _2Wp8I ZON4b PlM3e _2JVkc'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_vacancy_salary** - собираем зп  \n",
    "**get_vacancy_data** - собираем остальную информацию  \n",
    "**get_vacanies** - информация о количестве вакансий и страниц  \n",
    "**vacancies_scraping** - собираем ссылки вакансий для дальнейшего обхода  \n",
    "**err_log** - лог со статус-кодами неудачных запросов  \n",
    "**if not(self.mongo_collection.count_documents({'link':{'$eq': vacancy['link']}}))** - проверяем существование документа с такой ссылкой в базе. если есть, то данную вакансию не добавляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "    \n",
    "    def __init__(self, main_link, search_link, mongo_col):\n",
    "        self.headers = headers\n",
    "        self.main_link = main_link\n",
    "        self.search_link = search_link\n",
    "        self.start_link = ''\n",
    "        self.vacancies_total = 0\n",
    "        self.pages_total = 0\n",
    "        self.pages = 0\n",
    "        self.err_log = {}\n",
    "        self.mongo_collection = mongo_col\n",
    "        self.docs_before = self.mongo_collection.estimated_document_count()\n",
    "        self.dos_after = self.docs_before\n",
    "    \n",
    "    def get_vacancy_salary(self, parsed_html, params):\n",
    "        if self.main_link == hh_params['main_link']:\n",
    "            try:\n",
    "                currency = parsed_html.find(params['vac_salary_tag'], params['vac_salary_attrs'][0])['content']\n",
    "            except:\n",
    "                currency = None\n",
    "            try:\n",
    "                min_salary = int(parsed_html.find(params['vac_salary_tag'], params['vac_salary_attrs'][1])['content'])\n",
    "            except:\n",
    "                min_salary = None\n",
    "            try:\n",
    "                max_salary = int(parsed_html.find(params['vac_salary_tag'], params['vac_salary_attrs'][2])['content'])\n",
    "            except:\n",
    "                max_salary = None\n",
    "        else:\n",
    "            try:\n",
    "                vac_salary = parsed_html.find(params['vac_salary_tag'], params['vac_salary_attrs']).getText()\n",
    "            except:\n",
    "                vac_salary = None\n",
    "            if vac_salary != None:\n",
    "                if 'оговорённо' in vac_salary:\n",
    "                    min_salary = None\n",
    "                    max_salary = None\n",
    "                    currency = None\n",
    "                elif '—' in vac_salary:\n",
    "                    vac_salary = vac_salary.split('—')\n",
    "                    currency = vac_salary[1][-1]\n",
    "                    max_salary = int(''.join(i for i in vac_salary[1][:-1] if i.isdigit()))\n",
    "                    min_salary = int(''.join(i for i in vac_salary[0] if i.isdigit()))\n",
    "                elif 'от' in vac_salary:\n",
    "                    vac_salary = vac_salary.split()\n",
    "                    currency = vac_salary[-1]\n",
    "                    max_salary = None\n",
    "                    min_salary = int(''.join(i for i in vac_salary[1:-1] if i.isdigit()))\n",
    "                elif 'до' in vac_salary:\n",
    "                    vac_salary = vac_salary.split()\n",
    "                    currency = vac_salary[-1]\n",
    "                    max_salary = int(''.join(i for i in vac_salary[1:-1] if i.isdigit()))\n",
    "                    min_salary = None\n",
    "                else:\n",
    "                    vac_salary = vac_salary.split()\n",
    "                    currency = vac_salary[-1]\n",
    "                    max_salary = int(''.join(i for i in vac_salary[:-1] if i.isdigit()))\n",
    "                    min_salary = int(''.join(i for i in vac_salary[:-1] if i.isdigit()))\n",
    "            else:\n",
    "                min_salary, max_salary, currency = [None] * 3\n",
    "        return currency, min_salary, max_salary\n",
    "    \n",
    "    def get_vacancy_data(self, vacancies_links, params):\n",
    "        for curr_link in vacancies_links:\n",
    "            response = req.get(curr_link, headers=self.headers)\n",
    "            if response.status_code == 200:\n",
    "                parsed_html = bs(response.text,'lxml')  \n",
    "                vacancy = {}\n",
    "                try:\n",
    "                    vacancy['link'] = params['main_link'] + curr_link.split('.hh.ru', 1)[1]\n",
    "                except:\n",
    "                    vacancy['link'] = curr_link    \n",
    "                if not(self.mongo_collection.count_documents({'link':{'$eq': vacancy['link']}})):\n",
    "                    try:\n",
    "                        vacancy['name'] = parsed_html.find(params['vac_name_tag'], params['vac_name_attrs']).getText()\n",
    "                    except:\n",
    "                        vacancy['name'] = None\n",
    "                    try:\n",
    "                        vacancy['employer'] = parsed_html.find(params['vac_empl_tag'], params['vac_empl_attrs']).getText()\n",
    "                    except:\n",
    "                        vacancy['employer'] = None\n",
    "                    try:\n",
    "                        vacancy['location'] = parsed_html.find(params['vac_loc_tag'], params['vac_loc_attrs'][0]).getText()       \n",
    "                    except:\n",
    "                        try:\n",
    "                            vacancy['location'] = parsed_html.find(params['vac_loc_tag'], params['vac_loc_attrs'][1]).findParent().getText()\n",
    "                        except:\n",
    "                            vacancy['location'] = None\n",
    "                    vacancy['currency'], vacancy['min_salary'], vacancy['max_salary'] = self.get_vacancy_salary(parsed_html, params)\n",
    "                    vacancy['site_name'] = self.main_link\n",
    "                    self.mongo_collection.insert_one(vacancy)\n",
    "            else:\n",
    "                self.err_log[curr_link] = response.status_code\n",
    "                \n",
    "    def get_vacanies(self, params, search_text):\n",
    "        self.start_link = self.main_link + self.search_link + search_text\n",
    "        response = req.get(self.start_link, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            parsed_html = bs(response.text,'lxml')\n",
    "            if self.main_link == hh_params['main_link']:\n",
    "                try:\n",
    "                    self.vacancies_total = int(parsed_html.find(params[0], params[1])['data-totalvacancies'])\n",
    "                except:\n",
    "                    self.vacancies_total = 0\n",
    "                try:\n",
    "                    self.pages_total = int(parsed_html.find_all(params[2], params[3])[-1]['data-page']) + 1\n",
    "                except:\n",
    "                    if self.vacancies_total > 0:\n",
    "                        self.pages_total = 1\n",
    "                    else:\n",
    "                        self.pages_total = 0\n",
    "            else:\n",
    "                try:\n",
    "                    self.vacancies_total = int(parsed_html.find(params[0], params[1]).findChild().getText().split()[1])                         \n",
    "                except:\n",
    "                    self.vacancies_total = 0\n",
    "                try:\n",
    "                    self.pages_total = int(parsed_html.find_all(params[2], params[3])[-2].getText())\n",
    "                except:\n",
    "                    if self.vacancies_total > 0:\n",
    "                        self.pages_total = 1\n",
    "                    else:\n",
    "                        self.pages_total = 0\n",
    "            return self.vacancies_total, self.pages_total\n",
    "        else:\n",
    "            return print('что-то пошло не так: response.status_code', response.status_code)\n",
    "        \n",
    "    def vacancies_scraping(self, params):\n",
    "        self.err_log = {}\n",
    "        vacancies_links = []\n",
    "        for page in range(self.pages):\n",
    "            if self.main_link == hh_params['main_link']:\n",
    "                curr_link = self.start_link + f'&page={page}'\n",
    "            else:\n",
    "                curr_link = self.start_link + f'&page={page + 1}'\n",
    "            response = req.get(curr_link, headers=self.headers)\n",
    "            if response.status_code == 200:\n",
    "                parsed_html = bs(response.text,'lxml')\n",
    "                try:\n",
    "                    vacancies_links = [params['links_prefix'] + item.findChild(params['links_tags'][0], params['links_attrs'][0])['href']\\\n",
    "                                       for item in parsed_html.find_all(params['links_tags'][1], params['links_attrs'][1])]\n",
    "                except:\n",
    "                    vacancies_links = []              \n",
    "                if vacancies_links != []:\n",
    "                    self.get_vacancy_data(vacancies_links, params)\n",
    "            else:\n",
    "                self.err_log[curr_link] = response.status_code\n",
    "        self.docs_after = self.mongo_collection.estimated_document_count()\n",
    "        print(f'в коллекцию было добавлено: {self.docs_after - self.docs_before} док.')\n",
    "        print(f'на данный момент в коллекции: {self.docs_after} док.')\n",
    "        if self.err_log != {}:\n",
    "            print('не все прошло гладко - \"link\":\"response.status_code\"')\n",
    "            pprint(self.err_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### фунция выбора вакансий с заданной зп из базы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongo_get_salary(collections, salary):\n",
    "    cols = []\n",
    "    for col in collections:\n",
    "        cols.append(col.find({'$or':[{'min_salary':{'$gt':salary}}, {'max_salary':{'$gt':salary}}]}))\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_scraper = Scraper(hh_params['main_link'], hh_params['search_link'], mongo_hh)\n",
    "sj_scraper = Scraper(sj_params['main_link'], sj_params['search_link'], mongo_sj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### фомируем строку для поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что ищем? \n"
     ]
    }
   ],
   "source": [
    "search_text = input('Что ищем? ')\n",
    "if search_text == '':\n",
    "    search_text = 'Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_scraper.get_vacanies([hh_params['vac_tot_tag'], hh_params['vac_tot_attr'],\n",
    "                         hh_params['pages_tot_tag'], hh_params['pages_tot_attr']], search_text)\n",
    "sj_scraper.get_vacanies([sj_params['vac_tot_tag'], sj_params['vac_tot_attr'],\n",
    "                         sj_params['pages_tot_tag'], sj_params['pages_tot_attr']], search_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### задаем количество страниц для обхода на hh.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "на https://hh.ru найдено 6521 вакансий по запросу Python\n",
      "всего страниц 100\n",
      "Сколько страниц будем обходить? (по умолчанию 0) 1\n"
     ]
    }
   ],
   "source": [
    "print(f'на {hh_params[\"main_link\"]} найдено {hh_scraper.vacancies_total} вакансий по запросу {search_text}')\n",
    "print(f'всего страниц {hh_scraper.pages_total}')\n",
    "if hh_scraper.vacancies_total > 0:\n",
    "    try:\n",
    "        pages = abs(int(input('Сколько страниц будем обходить? (по умолчанию 0) ')))\n",
    "        if pages > hh_scraper.pages_total:\n",
    "            hh_scraper.pages = hh_scraper.pages_total\n",
    "        else:\n",
    "            hh_scraper.pages = pages\n",
    "    except:\n",
    "        hh_scraper.pages = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### задаем количество страниц для обхода на superjob.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "на https://www.superjob.ru найдено 95 вакансий по запросу Python\n",
      "всего страниц 5\n",
      "Сколько страниц будем обходить? (по умолчанию 0) 1\n"
     ]
    }
   ],
   "source": [
    "print(f'на {sj_params[\"main_link\"]} найдено {sj_scraper.vacancies_total} вакансий по запросу {search_text}')\n",
    "print(f'всего страниц {sj_scraper.pages_total}')\n",
    "if sj_scraper.vacancies_total > 0:\n",
    "    try:\n",
    "        pages = abs(int(input('Сколько страниц будем обходить? (по умолчанию 0) ')))\n",
    "        if pages > sj_scraper.pages_total:\n",
    "            sj_scraper.pages = sj_scraper.pages_total\n",
    "        else:\n",
    "            sj_scraper.pages = pages\n",
    "    except:\n",
    "        sj_scraper.pages = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в коллекцию было добавлено: 0 док.\n",
      "на данный момент в коллекции: 21 док.\n"
     ]
    }
   ],
   "source": [
    "hh_scraper.vacancies_scraping(hh_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в коллекцию было добавлено: 0 док.\n",
      "на данный момент в коллекции: 60 док.\n"
     ]
    }
   ],
   "source": [
    "sj_scraper.vacancies_scraping(sj_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "желаемая зарплата (по умолчанию 100000) \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    input_salary = abs(int(input('желаемая зарплата (по умолчанию 100000) ')))\n",
    "except:\n",
    "    input_salary = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacancy: Python разработчик | min_salary: 400000 | max_salary: 600000 | link: https://hh.ru/vacancy/34664011?query=Python\n",
      "vacancy: Web-программист Python (Middle/Senior) | min_salary: 150000 | max_salary: None | link: https://hh.ru/vacancy/34510621?query=Python\n",
      "vacancy: Kubernetes Engineer | min_salary: 200000 | max_salary: None | link: https://hh.ru/vacancy/34620646?query=Python\n",
      "vacancy: QA Automation Engineer | min_salary: 120000 | max_salary: 150000 | link: https://hh.ru/vacancy/32370952?query=Python\n",
      "vacancy: Ведущий разработчик Python / Software development / Team lead | min_salary: 200000 | max_salary: None | link: https://hh.ru/vacancy/34200113?query=Python\n",
      "vacancy: Инженер по тестированию / QA Engineer | min_salary: 80000 | max_salary: 110000 | link: https://hh.ru/vacancy/34620026?query=Python\n",
      "vacancy: QA Automation Engineer | min_salary: 120000 | max_salary: 150000 | link: https://hh.ru/vacancy/32370885?query=Python\n",
      "vacancy: QA Automation Engineer | min_salary: 120000 | max_salary: 150000 | link: https://hh.ru/vacancy/32370826?query=Python\n",
      "vacancy: Тестировщик НТ | min_salary: 115000 | max_salary: 115000 | link: https://www.superjob.ru/vakansii/testirovschik-nt-32605237.html\n",
      "vacancy: Web-разработчик React | min_salary: 90000 | max_salary: 110000 | link: https://www.superjob.ru/vakansii/web-razrabotchik-react-32675674.html\n",
      "vacancy: Тестировщик программного обеспечения | min_salary: 115000 | max_salary: 115000 | link: https://www.superjob.ru/vakansii/testirovschik-programmnogo-obespecheniya-32202847.html\n",
      "vacancy: Программист 3 ей категории, программист ABAP, разработчик SAP | min_salary: 50000 | max_salary: 120000 | link: https://www.superjob.ru/vakansii/programmist-3-ej-kategorii-29699029.html\n"
     ]
    }
   ],
   "source": [
    "for i in mongo_get_salary([mongo_hh, mongo_sj], input_salary):\n",
    "    for item in i:\n",
    "        print(f\"vacancy: {item['name']} | min_salary: {item['min_salary']} | max_salary: {item['max_salary']} | link: {item['link']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
